\section{Preface}

This works has been partially adapted from published work in the Astrophysical Journal, Volume 832, page 82 \citep{Johnson:2016rt}, with co-author Keren Sharon. The paper is adapted and partially reproduced here under the non-exclusive rights of republication granted by the American Astronomical Society to the paper authors.

For my part of this project, I created the fiducial model of ARES and all of the 300+ test models used to evaluate the systematic errors. I wrote nearly all of the text and created all of the figures.

\section{Abstract}
Until now, systematic errors in strong gravitational lens modeling have been acknowledged but have never been fully quantified. Here, we launch an investigation into  the systematics induced by constraint selection. We model the simulated cluster Ares 362 times using random selections of image systems with and without spectroscopic redshifts and quantify the systematics using several diagnostics: image predictability, accuracy of model-predicted redshifts, enclosed mass, and magnification. We find that for models with $>15$ image systems, the image plane rms does not decrease significantly when more systems are added; however, the rms values quoted in the literature may be misleading as to the ability of a model to predict new multiple images. The mass is well constrained near the Einstein radius in all cases, and systematic error drops to $<2\%$ for models using $>10$ image systems. Magnification errors are smallest along the straight portions of the critical curve, and the value of the magnification is systematically lower near curved portions. For $>15$ systems, the systematic error on magnification is $\sim2\%$. We report no trend in magnification error with fraction of spectroscopic image systems when selecting constraints at random; however, when using the same selection of constraints, increasing this fraction up to $\sim0.5$ will increase model accuracy. The results suggest that the selection of constraints, rather than quantity alone, determines the accuracy of the magnification. We note that spectroscopic follow-up of at least a few image systems is crucial because as models without any spectroscopic redshifts are inaccurate across all of our diagnostics.

%==================================================================================
%   INTRODUCTION
%==================================================================================
\section{Introduction}
\label{chap3:sec:introduction}

Since the discovery of the first gravitationally lensed arc in the field of cluster Abell 370 nearly three decades ago \citep{Soucail:1988kx}, astronomers have been taking advantage of the lensing magnification boost from massive galaxy clusters to observe the distant Universe. Gravitational lensing has the advantage of achromaticity, making spectral observations of these lensed objects comparable to unlensed sources in the field. Additionally, the strong lensing evidence traces the total mass distribution of the cluster, allowing for accurate reconstructions of the projected mass density of clusters, especially on small scales ($<100$ kpc) where other mass tracing methods are sensitive, yet lack the resolution of strong lensing. Lensing is sensitive only to mass and not to gas physics that can contribute to the uncertainties of mass scaling relations where the observable depends on the state of the hot intercluster medium.

However, one of the largest challenges in exploiting gravitational lensing remains in calibrating these ``cosmic telescopes". Both strong and weak lensing methods have been used extensively to measure the mass distribution of galaxy clusters. Numerous weak lensing surveys have allowed for a deep investigation into the statistical and systematic errors of weak lensing methods \citep{Shirasaki:2014qf,Applegate:2014jk,Massey:2013xy}. Similar analyses for strong lensing have lagged behind those of weak lensing for two main reasons: (1) accurate strong lens models require an exquisite image quality to robustly identify multiple images \citep{Kneib:1996kb}, and (2) the occurrence of strong lensing events is lower than weak lensing, making it more difficult to find strong lensing clusters to model. The {\it Hubble Space Telescope} (\hst) has been the primary workhorse for strong lensing observations since the installation of WFPC2. The probability of finding strong lenses is indeed small \citep{Wambsganss:2004vn,Bartelmann:1998fr}; but as predicted, several hundred strong lensing clusters have been found directly in several optical surveys \citep{Hennawi:2008mz,Gladders:2003zr} and after optical follow-up of clusters found in Xray-selected \citep{Postman:2012lr} and Sunaev-Zel'dovich effect-selected clusters \citep{Bleem:2015gf,Menanteau:2010fu}. Strong lensing mass estimates of the cores of these clusters when combined with other proxies for mass at larger scales will allow for measurements of the mass-concentration relation of galaxy clusters \citep{Merten:2015rz,Oguri:2012bs,Gralla:2011kx} across a range of cluster masses and redshifts. These strong lensing clusters highly-magnify numerous galaxies from the peak of cosmic star formation density around $z=2$ \citep{Bayliss:2011gf}, allowing for zoomed-in studies of star formation at a time when the Universe produced most of its stars \citep{Madau:2014qd}. Currently, strong lensing clusters are our best chance of finding the most distant galaxies at $z>8$, which may be responsible for re-ionizing the universe \citep[][to name a few]{McLeod:2015nr,Atek:2015qv,Zitrin:2014uq,Coe:2015qf}. With the ever increasing number of known strong lenses it will be important to fully understand how well we can quantify both the statistical and systematic errors in modeling strong lensing galaxy clusters.

Estimating the {\it statistical} errors in strong lens modeling has become nearly routine with the advancement in lens modeling codes to utilize Markov Chain Monte Carlo (MCMC) algorithms to adequately explore parameter spaces. The literature only mentions instances where systematic errors have been revealed between different models of the same cluster or when comparing new models of a cluster to earlier and obsolete models. For example, \citet{Smith:2009lr} found that including redshift information of the strong lensing constraints has a significant effect in constraining the slope of the mass distribution. Similarly, \citet{Johnson:2014tg} found that the magnification can vary beyond the statistical errors when the redshift information is added for a single system. \citet{Jauzac:2015xy} report an overall increase in magnification values for their new model of Abell 2744 using full-depth Hubble Frontier Fields (HFF) data; this effect has many possible causes: adding dozens of new image systems as constraints, including new spectroscopic redshifts, and/or correcting a misidentified image system.

\begin{figure*}
\center
\includegraphics[width=\textwidth]{Chap3/c3f1.pdf}
\caption[Strong lensing models from the literature]{The distribution of cluster strong lensing models from the literature, separated into number of strong lensing image systems with spectroscopic redshifts and those with unknown redshifts. The green stars represent the status of the HFF cluster lens models prior to HFF observations \citep{Johnson:2014tg,Richard:2014gf}, while the yellow stars show the most complete lens models to date on clusters with full HFF data \citep{Caminha:2016fk,Limousin:2016ty,Kawamata:2016nr,Treu:2016lr,Jauzac:2016dn,Jauzac:2014qd,Jauzac:2015xy}. We also include several other clusters from the literature, including those from the CLASH survey that do not overlap with the HFF clusters \citep{Zitrin:2015lq}. Other clusters include well-known lensing clusters such as Abell 1689 \citep{Diego:2015tg}, the Bullet Cluster \citep{Bradac:2009qd}, El Gordo \citep{Zitrin:2013hl}, Abell 1703 \citep{Limousin:2008lr}, Abell 2218 \citep{Eliasdottir:2007ve}, and many others \citep{Sharon:2015xe,Richard:2015lr,Richard:2010zp,Richard:2007rr,Sharon:2014fj,Bayliss:2014lr,Sharon:2012ly,Zitrin:2011qy}.}
\label{chap3:fig:slclusters}
\end{figure*}

While it is true that each individual method has its own systematic errors, all modeling methods are subject to errors due to the availability of constraints. The HFF clusters and Abell 1689, with a wealth of deep multi-wavelength imaging and spectroscopy, have unprecedented numbers of image systems identified and have some of the most precise lens models of clusters in existence \citep{Kawamata:2016nr,Treu:2016lr,Jauzac:2016dn,Diego:2015tg,Jauzac:2015xy,Jauzac:2014qd}. Yet, these clusters are seven unique lensing sight lines; in fact, most clusters only have a handful of multiple images (see Figure~\ref{chap3:fig:slclusters}). This reality stems from a few factors: (1) the aforementioned clusters are some of the most massive clusters, many showing signs of ongoing growth through mergers \citep{Jauzac:2015qf,Merten:2011fk}, resulting in larger lensing cross-sections, (2) have some of the deepest \hst\ data allowing for identification of fainter multiple image systems, and (3) have extensive spectroscopic campaigns which allow for the redshift confirmation of multiple image systems. Determining to what degree systematic errors are induced upon a lens model due to the availability of constraints is a high priority, especially for lower mass clusters which tend to lens fewer multiple image systems or massive clusters with shallow observations.

In this paper we begin to address several questions surrounding the topic of systematic errors in lens modeling. How does changing the number of constraining multiple image systems in a lens model affect the accuracy of strong lens models? Similarly, how does increasing the number of spectroscopic redshifts influence a model's accuracy? These questions are timely in this new era of strong lensing where high quality data are allowing for the most precise (i.e., low statistical uncertainty) models with high numbers of identified lensing constraints. Answering these questions will help guide the lensing community's focus to improve the quality of future strong lensing models. Spectroscopic campaigns are expensive: lensed galaxies, while magnified, are still faint and require long integrations on large telescopes, thus, we must determine their necessity for strong lens modeling. We show that it is critical for strong lens models to have at least a few spectroscopically-confirmed redshifts of image systems to dramatically reduce systematic errors.

This paper is organized as follows. We begin with a description of the experimental design in \S\ref{chap3:sec:experimental_design}. We describe the fiducial lens model in \S\ref{chap3:sec:lens_model} used for our analysis. In \S\ref{chap3:sec:methods} we describe our methodology for quantifying lens modeling systematics and report the results in \S\ref{chap3:sec:results}. Finally we summarize our work in \S\ref{chap3:sec:discussion} and discuss plans for future work in \S\ref{chap3:sec:future}. We assume a \LCDM\ universe with $\Omega_M=0.3$, $\Omega_\Lambda=0.7$, and $H_0=70\ \mathrm{km\ s^{-1}\ Mpc^{-1}}$. This cosmology yields an angular-physical scale of $1"=6.104$ kpc to the Ares cluster redshift $z=0.5$.


%==================================================================================
%  EXPERIMENTAL DESIGN
%==================================================================================
\section{Experimental Design}
\label{chap3:sec:experimental_design}
The goal of this study is to investigate quantitatively how the selection of strong lensing constraints, i.e., the redshifts and multiple images of strongly-lensed galaxies, affect lens models. We do this by generating 350 test models of the same gravitational lens, each test model uses a different random subset of the available constraints. The results of the test models are compared to a fiducial model that uses the full set of constraints as input. In this section we briefly describe our choices, while a thorough discussion is given in the following sections. 

The best-case-scenario fiducial model is a lens model of the simulated cluster Ares, a model that was initially computed for the purpose of the lens modeling comparison challenge \citep{Meneghetti:2016xe}. The fiducial model is constrained by 66 lensed galaxies with known redshifts. All test models will be compared to this fiducial model, which uses all lensing constraints and the true redshifts of the sources.

The parameter space that is covered by the test models is the number of lensed galaxies with spectroscopic redshifts, and the number of lensed galaxies without spectroscopic redshifts that are used to constrain the model. Each of those parameters is varied between zero and 25. For each combination of parameters we generate 10 models, with different galaxies selected randomly as constraints in each one. The tested combinations of number of lensing constraints with and without spectroscopic redshifts  cover scenarios similar to the HFF clusters, including early pre-HFF models with small number of constraints and as low as three spectroscopic redshifts, to the richest post-HFF datasets with hundreds of multiple images and dozens of new spectroscopic redshifts. 

We compare the test models on a few metrics: image plane rms as a measure of predictability of multiple images, model-predicted redshifts of systems without spectroscopic redshifts, mass distribution, and magnification. The results are compared with the fiducial model, rather than the simulation, in order to separate the systematic error induced by the constraints from other potential sources of systematics. The systematic error between the fiducial model and simulation truth may be sensitive to the exact modeling algorithm and parameterization choice, which is beyond the scope of this paper, yet will be important to investigate. We refer the reader to \citet{Meneghetti:2016xe} for current work, comparing different lensing methods. 

While we are only investigating this effect on a single method, this study is applicable to all strong lensing methods. Despite the variety of lensing methods (i.e., parametric versus non-parametric, see below), all methods are using the same lensing evidence to infer the mass distribution. 

%==================================================================================
%  STRONG LENS MODELING
%==================================================================================
%\section{Strong lens modeling}
%\label{chap3:sec:slmodeling}
%
%While diverse in computational algorithms, all strong gravitational lens modeling codes have a common goal: solve the lens equation 
%
%\begin{equation}
%\beta_{ij} = \theta_{ij} - \alpha_{ij}
%\end{equation}
%
%\noindent for the image plane positions $\theta_{ij}$ of each multiply imaged background source that map to location $\beta_{ij}$ in the source plane. The solution is the deflection field tensor $\alpha_{ij}$, which can be differentiated to solve for the projected surface mass density $\Sigma$,
%
%\begin{equation}
%\nabla_{ij}\alpha_{ij} = \frac{4\pi G}{c^2}\frac{\dls(\zl,\zs)}{\ds(\zs)} \dl(\zl)\ \Sigma,
%\label{eqn:SMD}
%\end{equation}
%
%\noindent where $\ds$, $\dl$, and $\dls$ are the angular diameter distances between the observer and the source at redshift $\zs$, between the observer and the lens at redshift $\zl$, and between the lens and source, respectively. When the lensing mass is contained to a single plane at $\zl$, then the deflection angle scales only with the lensing fraction
%
%\begin{equation}
%\frac{\dls}{\ds}(\zs) = \frac{\alpha_{ij}(\zs)}{\alpha_{ij}(z\rightarrow\infty)},
%\label{eqn:dlsds}
%\end{equation}
%
%\noindent which is a function of a single variable $\zs$. Thus, it is clear that both the image plane position $\theta_{ij}$ and the source redshift $\zs$ are needed to determine the full three-dimensional lensing geometry needed to constrain $\Sigma$.
%
%Strong lens modeling can include other observable strong lensing effects that constrain other first- and second-order derivatives of the lensing potential, including time delays, magnification ratios between different images of the same source, and flexion (distortion of the background source). These methods can be implemented in lens modeling codes, but are more prone to systematic error from the uncertainty of the observations themselves (i.e., lack of measured time delays, microlensing effects on magnification ratios, need for high-quality imaging for shape measurements). Measuring a centroid of an image of a lensed galaxy is straight-forward and typically the error in position is smaller than the errors in lensing due to cosmic variance and structure along the line of sight \citep{Limousin:2007fk}.
%
%There are generally two schools of thought for lens modeling codes: parametric and non-parametric methods. Parametric methods (e.g., Lenstool, \citealp{Jullo:2007lr}; glafic, \citealp{Oguri:2010gr}; gravlens, \citealp{Keeton:2001lr}; light-traces-mass, \citealp{Broadhurst:2005qy} and \citealp{Zitrin:2009qf}; GLEE, \citealp{Suyu:2012qf,Suyu:2010xy}) assume that the lensing potential and mass distribution of the lens can be expressed as a superposition of parameterized density distributions, and those parameters can be solved from the lensing evidence.  A common assumption for these models is that mass distribution follows that of the light (i.e., cluster member galaxies are assigned their own halos), however, this assumption can be applied more rigorously or loosely depending on the method. Non-parametric methods (e.g., SWunited, \citealp{Bradac:2008kx}; SaW lens, \citealp{Merten:2011fk}; LensPerfect, \citealp{Coe:2008mz}; WSLAP, \citealp{Diego:2007qf,Diego:2005ye}; Grale, \citealp{Liesenborgs:2010gf}) make no assumptions about the mass distribution and instead solve for each ``pixel" in the surface mass density of an adaptive grid with higher resolution near the constraints and peak of the density distribution. Some codes have been hybridized to include aspects of both parametric and non-parametric techniques \citep[ex., ][]{Jullo:2009ij}.

%==================================================================================
%   THE FIDUCIAL LENS MODEL
%==================================================================================
\section{The fiducial lens model}
\label{chap3:sec:lens_model}

\subsection{The simulated cluster Ares}
\label{chap3:sec:ares}

\begin{figure*}
\center
\includegraphics[width=0.9\textwidth]{Chap3/c3f2.pdf}
\caption[Surface mass density of Ares fiducial lens model]{The fiducial lens model of Ares. The grayscale image shows the projected surface mass density $\Sigma$ in units of the critical density $\Sigma_\mathrm{crit}=(c^2 \ds)/(4\pi G \dls \dl)$ at $z=2$. The locations of the multiple images used in the lens model are shown by the symbols, with colors indicating redshift. Images that match to the same source have the same redshift and are represented by the same symbol. The $z=2$ critical curve is shown by the solid white lines. The dashed white lines indicates the region where the model predicts multiple images for $z=2$. The red crosses and blue x's mark the centers of the two cluster halos and four galaxy halos listed in Table~\ref{chap3:tab:params}, respectively. The gold dotted boxed region indicates the pixels used to generate the plots in Figures~ \ref{chap3:fig:histograms},  \ref{chap3:fig:specz_fraction}, \&  \ref{chap3:fig:single_compare}.}
\label{chap3:fig:hst}
\end{figure*}

A full description of the Ares simulated cluster is given in \citet{Meneghetti:2016xe}. In short, the Ares cluster simulation is designed to mimic a massive cluster that is an efficient gravitational lens. The publicly available software MOKA \citep{Giocoli:2012lr} is used to create simulated lensing signals from clusters, including a number of scaling relations derived from N-body simulations, a mass-concentration relation, a subhalo mass function, and subhalo tidal stripping effects on truncation radii. The main cluster potential is composed of two triaxial clumps with masses $1.8\times10^{15}\ \mathrm{M_\odot}$ and $1.3\times10^{15}\ \mathrm{M_\odot}$ following the Navarro-Frenk-White profile \citep[NFW;][]{Navarro:1997qa}, separated by $\sim570$ kpc, along with two central cluster galaxies near the centers of these gravitational wells, which are modeled by triaxial profiles. The galaxy-scale halos are modeled as singular isothermal spheres.

The baryonic component of Ares follows a halo-occupation distribution (HOD) technique, where it is assumed that the stellar mass of a galaxy is tightly correlated with the depth of the gravitational potential well that it occupies. The B band luminosities are assigned to each halo by MOKA using the relations described in \citet{Giocoli:2012lr}, which follow closely with the results by \cite{Wang:2006kk}. Then, a spectral energy distribution is assigned to each galaxy based on this luminosity and
empirical relations such as the morphology-density relation and the fraction of morphological types observed in clusters as a function of radius. Foreground galaxies and stars are added to the imaging; however, there is no additional mass along the line of sight to the cluster associated with these interlopers.

To simulate the lensed background Universe, the lensing signal from the cluster Ares is input into SkyLens \citep{Meneghetti:2010mi,Meneghetti:2008oz}, which ray traces real galaxies from the Hubble Ultra Deep Field \citep{Beckwith:2006rt} to the image plane. SkyLens creates mock \hst\ imaging of the results, which match the depth and wavelength coverage of the HFF observations.

The primary utility of Ares is for the on-going HFF lens modeling comparison study \citep{Meneghetti:2016xe}. The same teams that modeled the HFF clusters, using different methods, were invited to compute lens models for Ares. Each team was given the simulated imaging along with a catalog of all the multiple image systems and redshifts, but were initially blind to the true mass distribution. The goal of this study is to identify how different methods reproduce the true mass and magnification of a HFF-like cluster when given identical inputs and to identify systematic errors across lens models that can be addressed when creating the best lens models. The initial ``blind" modeling took place mid-2014, after which the mass and magnification were unveiled to the modeling teams. Our goals in this work can be thought of the tangent of those for the comparison study: rather than determine the systematics for different modeling methods using identical inputs, we are testing with a single method how varying the quantity and redshift information of constraints induces systematic errors.

\subsection{The lens model}
\label{chap3:subsec:fiducial_model}

We follow a similar methodology for modeling Ares as \citet[Chapter 2]{Johnson:2014tg}. We use the publicly-available parametric modeling software Lenstool \citep{Jullo:2007lr}, which utilizes a Bayesian MCMC to explore the parameter space of the lensing distribution. We construct a lens model using all of the available lensing evidence that accurately reproduces the simulation mass and magnification. We refer to this model as the fiducial model, representing the best possible model we can create with our methods when all of the information (images, redshifts, mass distribution, etc.) is revealed. The fiducial model critical curves and images are shown in Figure~\ref{chap3:fig:hst}.


\begin{deluxetable}{cccccccc}
\tablecolumns{8}
\tabletypesize{\scriptsize}
\tablewidth{0pt}
\tablecaption{List of fiducial lens model constraints}
\tablehead{\colhead{} & \colhead{$x$ (")} & \colhead{$y$ (")} & \colhead{$e$} & \colhead{$\theta$ ($^\circ$)} & \colhead{$r_\mathrm{core}$ (kpc)} & \colhead{$r_\mathrm{cut}$ (kpc)} & \colhead{$\sigma_0$ ($\mathrm{km\ s^{-1}}$)}}
\startdata
cluster halo \#1 & $-20.3^{+0.1}_{-0.2}$ & $-33.3^{+0.1}_{-0.3}$ & $0.510^{+0.003}_{-0.016}$ & $50^\pm0.5$ & $100^{+3}_{-2}$ & [1500] & $1250^{+5}_{-7}$ \\[5pt]
cluster halo \#2 & $40.8^{+0.1}_{-0.3}$ & $40.9^{+0.4}_{-0.2}$ & $0.54^{+0.00}_{-0.05}$ & $74^{+1}_{-2}$ & $56\pm3$ & [1500] & $765^{+9}_{-5}$ \\[5pt]
galaxy halo \#1 & [-33.0] & [-63.6] & [0] & \nodata & [0] & $90^{+70}_{-0}$ & $240^{+130}_{-0}$ \\[5pt]
galaxy halo \#2 & [-20.0] & [-32] & $0.13^{+0.03}_{-0.07}$ & $156^{+27}_{-6}$ & [0] & [1500] & $502^{+10}_{-5}$ \\[5pt]
galaxy halo \#3 & [40.0] & [40.0] & $0.77^{+0.04}_{-0.20}$ & $5^{+5}_{-6}$ & [0] & [1500] & $290^{+6}_{-29}$ \\[5pt]
galaxy halo \#4 & [-4.0] & [22.0] & [0] & \nodata & [0] & [1500] & $213^{+4}_{-11}$ \\[5pt]
\hline \\[-5pt]
$L^\star$ galaxy & \multicolumn{4}{c}{$m_\star=20.00,\ z=0.5$ (ACS F606W)} & 0 & 20 & 100
\enddata
\vspace{-20pt}
\tablecomments{The ellipticity is defined as $e=(a^2-b^2)/(a^2+b^2)$, where $a$ and $b$ are the semimajor and semiminor axes, respectively. The position angle is measure counterclockwise from the $+x$ axis. Parameters in square brackets are not optimized in the model. Errors represent the $1\sigma$ spread in values from the MCMC.}
\label{chap3:tab:params}
\end{deluxetable}


The mass distribution is parameterized by pseudo-isothermal elliptical mass distributions \citep[PIEMD or dPIE; ][]{Limousin:2005cr}; the profile is described by a fiducial velocity dispersion $\sigma_0$ to normalize the potential, an ellipticity and position angle, and core radius $r_\mathrm{core}$ and cut radius $r_\mathrm{cut}$ which control the inner and outer slopes of the profile, respectively. A summary of those halo parameters are given in Table \ref{chap3:tab:params}. We use two halos to represent the dark matter cores in the cluster, which were also included in our ``blind" lens model. We include the masses of galaxy cluster members as small perturbers to the smooth dark matter potential of the cluster. The galaxies are selected by red-sequence membership and their halo parameters are scaled by their brightness following

\begin{eqnarray}
\sigma_0&=& \sigma_0^\star \left(\frac{L}{L^\star}\right)^{1/4}, \nonumber \\
r_\mathrm{core} &=& 0 \\
r_\mathrm{cut} &=& r_\mathrm{cut}^\star \left(\frac{L}{L^\star}\right)^{1/2} \nonumber
\end{eqnarray}

\noindent where $\sigma_0^\star, r_\mathrm{core}^\star, r_\mathrm{cut}^\star$ are the parameters of an $L^\star$ galaxy at the simulated cluster redshift $z=0.5$. For four cluster galaxies (including the two brightest galaxies in both cores), we allow some of the parameters to deviate from the scaling relations and be guided by the lensing of nearby multiple images, as we routinely do in lens models of real clusters. Galaxy halo \#1 (as indicated in Table \ref{chap3:tab:params}) is a massive galaxy that has a significant impact on the location of the critical curve in the southwestern portion of the image plane. Galaxy halos \#2 and \#3 lie near the centers of the two massive cluster halos and thus have an impact on the locations of the radial arcs across the entire cluster. The fourth galaxy halo is massive enough to produce its own protrusion of the tangential critical curve created by the two massive cluster halos, thus influencing the lensing of several nearby images. These four galaxies are needed for models with many constraints; however, their parameters are more difficult to constrain in the case when there are no images within a few arcseconds of the halo.

Our treatment of the scaling relations for Ares deviate from those of the models in \citet{Johnson:2014tg} due to the construction of the simulation. We did not include shape information from the light distribution to guide the galaxy shapes in the lens model and instead modeled the halos as single isothermal spheres ($\mathrm{ellipticity} = 0$, $r_\mathrm{core} = 0$) as to match closely to the parameterization of the simulation. We ran a simple optimization to explore which scaling parameters produce a close match between the simulated halos and lens model halos. All three of these parameters are highly degenerate when determining the mass of a halo and thus no single parameter combination was determined to be a significantly better fit over others. Additionally, the typical scale of $r_\mathrm{cut}$ is several tens to a hundred kiloparsecs; at this scale the halo of a galaxy begins to overlap with neighboring galaxies and the main cluster potential starts to dominate the local surface mass density. Thus, $r_\mathrm{cut}$ is difficult to constrain. We selected a parameter combination that was reasonable with those of previous strong lensing models and matched well with the simulation: $\sigma_0^\star=100\ \mathrm{km\ s^{-1}}$, $r_\mathrm{cut} = 20$ kpc, and $m_\mathrm{F606W}^\star=20.0$. Due to a different choice of scaling relations and photometric band used for scaling, we do not expect the simulation and lens model to match perfectly. Our goal with this optimization is to minimize the effects of scaling parameter selection on the overall systematic errors of the lens model we are attempting to measure. The mass of the fiducial model is reconstructed with an accuracy of $-0.24^{+0.23}_{-0.30}\%$ of the simulation mass within 500 kpc of the cluster center.

A list of simulated multiple images, their locations, and their redshifts was released along with the simulated data. We altered this list to comply more closely with one that would have been created by a lens modeler identifying images by eye. We made slight adjustments ($<0.1"$) to the location of the image constraints to match the same features of a galaxy in all its multiple images. Additionally, for three image systems with more extended sources, we include multiple positional constraints corresponding to different unique features within the lensed galaxy. Finally, we purged the list of images that would not be detectable if the search was done by eye (ex., images behind a large galaxy, too faint to be visible), such that our identification quality matched that of deep HFF-based lens models. Figure~\ref{chap3:fig:hst} shows the locations and redshifts of our final list of 232 multiple images from 66 unique sources ($\Nfid=66$) with $0.91<z<5.80$ (and are listed in Table \ref{app:tab:constraints} in the Appendix). The image plane rms for the fiducial lens model of Ares for all 66 image systems is $0.58"$ (see \S\ref{chap3:subsec:rms} for definition and further discussion), which is on par with the scatter quoted for Lenstool-based models of the HFF clusters \citep{Treu:2016lr,Jauzac:2016dn,Sharon:2015xe,Jauzac:2015xy,Jauzac:2014qd,Johnson:2014tg,Richard:2014gf}. 

%==================================================================================
%   METHODOLOGY
%==================================================================================
\section{Test Models}
\label{chap3:sec:methods}

The fiducial model of Ares represents an idealized scenario for creating a lens model, one where many image systems are known with certainty and all systems have confirmed redshifts. However, this scenario would be considered extreme compared to models of real clusters, which typically have fewer multiple image systems and even fewer spectroscopic redshifts. To represent types of cluster lens models that currently exist, we create new models of Ares using ``jacknifed" subsets of images from the full list of image systems. We randomly select $n=0,5,10,15,20,25$ image systems with their known (spectroscopic) redshifts and $m=0,5,10,15,20,25$ image systems with unknown redshifts and remodel the cluster with a total number of image systems $N=n+m<\Nfid$. For the $m$ systems without known redshifts, we only include image positions as constraints in the model and leave redshift as a free parameter with a uniform random prior probability distribution function ranging $0.6<z<7$ (see \S~\ref{chap3:subsec:photoz} for a treatment/discussion of photometric redshifts). We run 10 different models for each combination of $n,m$ for better statistics, each with a unique set of images. We refer to these models with different $n,m$ as the ``test models" from here-on.

We choose to run the test models with the same parameterization as the fiducial model (i.e., same free and fixed parameters and priors as Table \ref{chap3:tab:params}) so that we can directly compare these models with the fiducial model. It is true that models with lower $N$ may not be able to constrain all of the free parameters of the fiducial model. By basing the parameterization of the test models off of the fiducial model, we are including some knowledge a priori about the mass distribution for which a given set of $N$ images alone may not be able to provide enough evidence (i.e., existence of a secondary halo, shape of central galaxies, etc.). In a truly blind scenario, it is likely a lens modeler would choose a different parameterization; however, the choice of parameterization on a model-by-model basis is not easy to simulate. With this caveat in mind, the systematic errors for smaller $N$ stated here are likely lower limits that do not reflect choice in parameterization as a function of $N$.

Lens modeling is a computationally-intensive task, as proper modeling in the image plane entails inverting the lens equation and computing the scatter for each multiple image, which requires scanning many image plane pixels for matching source plane positions. The newest versions of Lenstool (v6.7 and above) have built-in parallelization that dramatically reduces computation time; however, a model can take days up to weeks to run under optimal parallelization. Since we ran all of the models for this work with image plane optimization, the computation time is considerable. We used the Flux High Performance Cluster at the University of Michigan to compute these models, using Lenstool version 6.8 on eight nodes with 20 core processors (two ten-core 2.8 GHz Intel Xeon E5-2680v2 processors) and 96 GB RAM over the course of 4 months, where all 350 test models ran continuously in queue. In order to increase the number of models running in parallel on a single node, the models with fewer total image systems $N$ were assigned to run below node capacity, such that the $N_{cores}=\mathrm{floor}(N/2)+1$ and up to 20 cores. Each model was run with the Lenstool parameter for Bayesian rate set to the maximum of 0.5 and for only a set of 5010 models in the MCMC. The total wall time for the test models clocks in at $\sim329,000$ core-hours.

%==================================================================================
%   RESULTS
%==================================================================================
\section{Results}
\label{chap3:sec:results}

The different combinations of $n$ (spectroscopic redshifts) and $m$ (free parameter / unknown redshifts) result in 35 model families. For better statistics, each of these combinations was sampled 10 times, for a total of 350 models. We now compare the lensing outputs of these 35 model families against each other and against the fiducial lens model.  Below, we investigate the dependence of several diagnostics on the total number of lensed galaxies used as constraints ($N=n+m$), the number of spectroscopic redshifts ($n$), and the fraction of spectroscopic redshifts ($n/N$). 

\subsection{Image predictability}
\label{chap3:subsec:rms}

The image plane rms scatter of multiple image systems is a measure of how accurately a lens model can reproduce the locations of images. It is effectively the quantity that is being minimized during image plane optimization (the $\chi^2$ is the image plane rms normalized by the estimated error in image position). The locations of multiple images are transformed to the source plane and then relensed to other locations in the image plane and the scatter is computed based on the separation of the predicted and observed locations.

To see the effects of adding image systems with spectroscopic or unknown redshifts, we compute the image plane rms using all 66 image systems and their true redshifts for each of the test models in Figure~\ref{chap3:fig:rms} (top panels). This test shows how well the model can reproduce lensing in many parts of the image plane, not only where constraints are located. We find that increasing the total number of systems $N$ decreases the rms scatter asymptotically toward the fiducial model rms. We also find that this trend is true for increasing number of spectroscopic redshifts $n$ and only weakly for increasing free parameter redshifts $m$ for models with $n<10$. 
Models will improve significantly in image predicting power when more image systems are included in the model, especially those with spectroscopic redshifts. However, this effect plateaus for models with either $N>25$ or $n>20$, when the exact selection of the constraints rather than quantity determines the level of systematic error in image plane rms. In clusters with many lensed galaxies, modelers often rely on preliminary lens models in order to predict the locations and identify new sets of lensed images. This result shows the importance of having spectroscopic redshifts in these preliminary models, as at least $n>10$ spectroscopic redshifts are needed in order to robustly distinguish between multiple image candidates based on their model-predicted location ($\mathrm{rms}<1.0"$). In particular, all models with no spectroscopic redshifts have poor rms.

It is worth emphasizing that the image plane rms we computed using all 66 image systems would not be the value quoted for a typical lens model of a real cluster in the literature. In reality, modelers compute the rms only for the image systems used in the model and use the redshift solutions from the best fit model for the systems without spectroscopic redshifts (not the true redshifts, as these are not known). To demonstrate this discrepancy, we plot the rms value computed using only the image systems and the model-derived redshifts\footnote{This image plane rms corresponds to the value from the output file in the Lenstool software for the best fit model.} in Figure~\ref{chap3:fig:rms} (bottom panels). We see that this value tends to be much lower than the fiducial value, and the trends for this rms are the reverse of the top panels. The rms value computed in the bottom panels is a measure of goodness of fit, adding more free parameter redshifts increases model flexibility and adding more spectroscopic systems increases the number of constraints without increasing the number of free parameters. Models that are less flexible with more constraints produce higher rms values in the bottom panels, indicating a worse model fit; however, these models are better at predicting the locations of images across the entire image plane, as indicated by the rms in the top panels.

Figure~\ref{chap3:fig:rms} demonstrates the need for caution when relying on the image plane rms value to judge lens model fidelity, especially when many image systems with unknown redshifts are included in the model. Since the deflection field scales with distance to the source, the image plane rms will depend on the redshift of the source. For spectroscopic systems, the redshift is fixed; however, the free parameter redshift of image systems included in the model, by the construction of a maximum likelihood optimization, will take on a value for the redshift which helps to minimize the overall image plane rms, which may or may not coincide with the correct redshift. While models without free parameter redshifts have flexibility and report low image plane rms, they have the potential to encounter parameter degeneracies between the mass distribution and source plane redshifts.

\begin{figure*}
\center
\includegraphics[width=\textwidth]{Chap3/c3f3.pdf}
\caption[Image plane rms vs. spec-z fraction of test models]{Image plane rms for all the test models plotted versus fraction of spectroscopic redshifts, total number of image systems, number of spectroscopic redshifts, and number of free parameter redshifts. The colors and shapes of the points represent the number of spectroscopic redshifts and number of free parameter redshifts used in the model, respectively (see legend at top). The top panels show the image plane rms values computed for all 66 image systems using the true redshift values. The bottom panels show the image plane rms values computed only from the images used as constraints in the lens model and model predicted redshifts.  The dashed line indicates the value of the image plane rms for the fiducial model and is computed from all 66 image systems and true redshifts.}
\label{chap3:fig:rms}
\end{figure*}

\begin{figure*}
\includegraphics[width=\textwidth]{Chap3/c3f4.pdf}
\caption[Error in redshift parameter of test models]{Error in best fit model redshift parameter of image systems used as constraints in sets of 10 models using different numbers of spectroscopic redshifts and free parameter redshifts. The redshifts are plotted in terms of the lensing fraction $\dls/\ds$, a function of source redshift which scales the deflection angle of the lens. The error bars represent the $1\sigma$ errors computed from the MCMC chain. The colors match the free parameter redshifts used in the same model. The gray line indicates the rolling average across $\dls/\ds$ from all models. The value at the bottom of each is the weighted mean error in the lensing fraction for all models. Note that the top row ordinates have a different scale from the other plots.}
\label{chap3:fig:dlsds}
\end{figure*}

\subsection{Model-predicted redshifts}

We investigate how accurately models using free parameter redshifts predict the true redshift of those image systems. Figure~\ref{chap3:fig:dlsds} shows the error between model-derived redshift and the true redshift of the system. We plot these errors in terms of the lensing fraction $\dls/\ds$ rather than $\zs$; as shown in (\ref{intro:eqn:dlsds}), the deflection angle tensor $\alpha_{ij}$ scales linearly with the lensing fraction. The typical error in model predicted $\dls/\ds$ is $<2\%$ in all cases and tends to be lower for models that have higher fractions of image systems with spectroscopic redshifts. Interestingly, models with low fractions of image systems that have spectroscopic redshifts tend to predict redshifts solutions that are more often biased to higher values for systems with  $z>2$. Nearly all of the model-predicted $\dls/\ds$ of models with $n=0$ are biased high by 5-10\%.

\subsection{Mass}
In Figure~\ref{chap3:fig:mass}, we plot the projected mass profile of the cluster for the fiducial model (top) and residual from the fiducial model for all of the test models (bottom). We find that the errors in the enclosed mass are typically $<4\%$ out to 1 Mpc for models with $n>0$. Models with $n=0$ are generally biased toward lower masses, which is consistent with model predicting higher redshifts for the free parameter image systems. For models with $n>0$, the errors are generally lowest at radii around the ``arc radius", $r_\mathrm{arcs}=305$ kpc, defined as the median image plane projected distance of images used as constraints in the fiducial model; it is comparable to the formal definition of the Einstein radius. Test model combinations with at least five spectroscopic redshifts have errors $<1\%$ around the arc radius.

\begin{figure*}
\center
\includegraphics[width=\textwidth]{Chap3/c3f5a.pdf}
\includegraphics[width=\textwidth]{Chap3/c3f5b.pdf}
\caption[Radial mass profile of Ares fiducial lens model and of test models]{(Top) radial mass profile for the fiducial model. The histogram shows the projected radii of all the constraints used in the model. The dashed vertical line is the median projected radius of the arcs at $r_\mathrm{arcs}=305$ kpc. (Bottom) Radial mass profile residuals from the fiducial model for all test models with different numbers of spectroscopic and free parameter redshifts used as constraints. The dotted lines represent the $1\sigma$ statistical error in the fiducial model mass profile estimated from the MCMC. The dashed vertical line matches $r_\mathrm{arcs}$ from the top plot. Note: the top row ordinates have a different scale from the other plots.}
\label{chap3:fig:mass}
\end{figure*}

\subsection{Magnification}
\label{chap3:subsec:magnification}
%The magnification describes the amplification of the solid angle of a lensed object from source plane to image plane and is derived from the lensing Jacobian tensor
%
%\begin{equation}
%A_{ij}\equiv \frac{\partial\beta_{ij}}{\partial\theta_{ij}}=\delta_{ij}-\frac{\partial\alpha_{i}}{\partial\theta_{j}},
%\end{equation}
%
%\noindent which describes the translation from source plane $\beta$ to image plane $\theta$. The magnification $\mu$ is the inverse determinant of this tensor,
%
%\begin{equation}
%\mu = \frac{1}{|\det A_{ij}|},
%\end{equation}
%
%\noindent which becomes a non-linear combination of first-order derivatives of $\alpha$. Based on its complexity, we expect the magnification factor to have more complicated relations with observable quantities than the diagnostics discussed earlier.

\begin{figure*}
\center
\includegraphics[width=1.0\textwidth]{Chap3/c3f6.pdf}
\caption[Error in magnification of test models]{Median error in the magnification maps for $z=2$ for each set of models with various numbers of constraints with spectroscopic redshifts and free parameter redshifts. The error is computed with respect to the magnification map of the fiducial model. The $z=2$ critical curve for the fiducial model is shown in the solid green and the region enclosed by the dashed green line is the extent of image multiplicity for sources at $z=2$. The top-left panel shows the statistical errors in magnification for each pixel of the fiducial model. Each panel has dimensions $200"\times200"$.}
\label{chap3:fig:magnification_bias}
\end{figure*}

In Figure~\ref{chap3:fig:magnification_bias}, we plot the error in magnification at each image plane position corresponding to a source at $z=2$ for each test model combination (i.e., median magnification of each pixel across all models with same $n,m$) relative to the fiducial model magnification. These maps effectively show the bias in magnification when selecting $n,m$. We choose to display $z=2$ because it corresponds to a middle value of $\dls/\ds$ for all the sources used as constraints.

For models with $n>0$, the magnification errors are all quite similar. Across all models the magnification is most accurate in regions of lower magnification ($\mu<10$) and along the straight portion of the critical curve, the region where most of the multiple images are located. A straight critical curve implies that the vector of the deflection angle is nearly constant in terms of direction and only changes in amplitude; solving the lens equation in this region becomes one dimensional. At the high-curvature portions of the critical curve, the tangential shear is strong and the deflection angle changes rapidly in both amplitude and direction. Also, objects here are highly magnified, but their image multiplicity becomes unity. These singly-imaged sources are indeed strongly lensed, but are not used as strong lensing constraints for this modeling method. Some methods can use single images as constraints; however, doing so greatly increases computing time in order to reject models producing multiple images. Additionally, the flexion of these highly magnified single-image systems could be included in modeling methods to better constrain the mass distribution where there are no multiple images \citep[ex.,][]{Cain:2011ab}.

\begin{figure*}
\center
\includegraphics[width=1.0\textwidth]{Chap3/c3f7.pdf}
\caption[Range of error in magnifications of test models]{Interquartile range (IQR) of errors in the magnification maps for $z=2$ for each set of models with various numbers of constraints with spectroscopic redshifts and free parameter redshifts. The error is computed with respect to the magnification map of the fiducial model. The $z=2$ critical curve for the fiducial model is shown in the solid green and the region enclosed by the dashed green line is the extent of image multiplicity for sources at $z=2$. The top-left panel shows the statistical error range in magnification for each pixel of the fiducial model. Each panel has dimensions $200"\times200"$.}
\label{chap3:fig:magnification_spread}
\end{figure*}

While Figure~\ref{chap3:fig:magnification_bias} shows the bias of the magnification for all regions in the image plane over a slew of different models, Figure~\ref{chap3:fig:magnification_spread} shows the interquartile range (IQR\footnote{We define the IQR as the difference between the 75th and 25th percentile models. These percentiles correspond to the average magnification between the 8th/9th-ranked and 2nd/3rd-ranked models, respectively.}) in magnification, i.e., how consistent the systematic errors in magnification are relative to the fiducial models when different sets of constraints are used for the same $n,m$. We plot the IQR to eliminate the effects of potential outlying models in our analysis. We see similar trends to those of Figure~\ref{chap3:fig:magnification_bias}: the IQR in magnification between models is lower for regions with low magnification and along the straight portion of the critical curve. We see a very clear trend with reduced spread in magnification error throughout most of the image plane with higher $N$.

\begin{figure*}
\center
\includegraphics[width=1.0\textwidth]{Chap3/c3f8.pdf}
\caption[Histogram of pixelized-magnification errors of test models]{Histograms of magnification error ($z=2$) for the region of pixels shown in Figure~\ref{chap3:fig:hst} for models with different numbers of spectroscopic and free parameter redshifts. Each color shade represents a unique model constructed with different random subsets of images used as constraints. The top-left panel shows the $1\sigma$ statistical errors of each pixel in the fiducial model. The black bar on top shows the typical $1\sigma$ statistical error for a test model. The dashed vertical line and horizontal grey bars show the median and $1\sigma$ range in magnification error distribution of all test models combined, and these values are displayed in each panel.}
\label{chap3:fig:histograms}
\end{figure*}

We attempt to quantify the systematic errors in Figure~\ref{chap3:fig:histograms} by looking at the distribution of magnification errors across the image plane. We create histograms of the magnification error for each pixel for each individual test model. We only examine pixels located in a rectangular region with bounds selected arbitrarily such that it lies in the lower right $(+x,-y)$ aligned roughly with the critical curve of the cluster, to avoid pixels near the curved portion of the critical curve. This region of pixels is shown in Figure~\ref{chap3:fig:hst}. We also only select pixels with $\mu_\mathrm{fiducial}<20$ to avoid high magnifications induced locally by cluster member galaxies. We see that models with lower $N$ tend to produce magnifications that are typically biased low, however, beyond $N\geq25$ the distributions of models appear to be similar and with negligible bias, with a typical error of about 2\%.

It is noticeable across all test models that the variation in the distribution of magnifications is quite significant for low total number of image systems, even amongst test models with identical $n,m$. This indicates that it is not necessarily quantity of image systems or redshifts, but rather the selection of these constraints that drives systematic error. We examined closely a few of the models with outlying distributions in Figure~\ref{chap3:fig:histograms} and found that the random selection of spectroscopic redshift systems for those models was either unevenly distributed spatially in the image plane or unevenly distributed in redshift space.

\begin{figure*}
\center
\includegraphics[width=\textwidth]{Chap3/c3f9a.pdf}
\includegraphics[width=\textwidth]{Chap3/c3f9b.pdf}
\caption[Magnification error vs fraction of spec-z and vs total number of images for test models]{The relative magnification error ($z=2$) for the region of pixels shown in Figure~\ref{chap3:fig:hst} for all the test models versus fraction of spectroscopic redshifts $n/N$ (top) and total number of image systems $N$ (bottom). The values are median and $1\sigma$ range of values within the region for the best fit models. The different shapes and colors indicate the number of free parameter redshifts and spectroscopic redshifts used in the model, respectively. The dashed lines indicated the $1\sigma$ statistical errors for the fiducial model. The gray contours represent the 1, 2, and 3$\sigma$ ranges for each block of the test models in fraction/number of systems. Note: the abscissa values for the test models within each grouping of test models have been slightly offset horizontally for display purposes. There is a clear trend of improved magnification error with the total number of images, but no dependence on the fraction of spectroscopic redshifts.}
\label{chap3:fig:specz_fraction}
\end{figure*}

In Figure~\ref{chap3:fig:specz_fraction}, we plot the relative magnification error and spread for all test models (defined as they are in Figure~\ref{chap3:fig:histograms}) versus the fraction of spectroscopic redshifts $n/N$ and total number of image systems $N$. We report no clear trend in magnification error or spread with spectroscopic redshift fraction, except that models with no spectroscopic redshift are biased toward lower magnifications and have a $1\sigma$ spread of about 3\%.  There is a clear trend in decreasing systematic error with $N$, and for $N\geq25$, the $1\sigma$ magnification error stays constant at about 1\%.

%==================================================================================
%   DISCUSSION
%==================================================================================
\section{Discussion}
\label{chap3:sec:discussion}

\subsection{Number of image systems in a model}
The selection of image systems with or without confirmed redshifts is usually not a choice in building a lens model, as for most clusters the number of constraints is small regardless and thus modelers require a minimum number of constraints to build a statistically meaningful model. However, the paradigm has changed with the onset of the HFF, where there is a seemingly-infinite number of multiple image systems and several spectroscopic redshifts from which to build our models. Statistical errors in these scenarios are now much lower than the systematics, so including or rejecting a candidate image systems in a model is now a question of its influence on systematic error.  Our results show that models reach a threshold in systematic errors across all diagnostics once $N\geq25$ and $n>0$ have been established. For the test models, the identification of images and redshift measurements are known with certainty; however, that is not the case in real scenarios. Beyond this threshold, rejecting an incorrect image system or redshift based on a high degree of uncertainty will likely deflate rather than inflate systematic errors.

\subsection{Finding new multiple image systems}
From Figure~\ref{chap3:fig:rms} we learned that spectroscopic redshift systems are needed to improve the image plane rms of a model when few constraints are available ($N<15$). While this may have its applications post-modeling, image predictability is most applicable for improving an existing model by using its deflection to find new multiple image systems. The results of this work emphasize the importance of including more spectroscopic redshifts early on in the stages of lens modeling, as models built using fewer spectroscopic redshifts have more error in predictability and thus are more likely to find false image systems. While the brightest and largest multiple image systems are obvious by morphology and color without confirmed redshifts, fainter and smaller systems are more ambiguous, especially where many faint galaxies at all redshifts pass the detection limit and could be confused for lensed galaxy candidates.

\subsection{Constraining mass}
Mass profiles of galaxy clusters are quite robust to redshift confirmation of multiple image systems. Figure~\ref{chap3:fig:mass} shows that including more image systems in a model with at least a handful of spectroscopic redshifts helps to reduce systematic errors in mass profile. The systematic error on total projected mass out to 1 Mpc is only 2\% for models with $N\geq25$ and $n>0$ (4\% for $N<25$). This result is promising for using strong lensing clusters for cosmology -- future large area surveys will find hundreds of clusters and complete spectroscopic follow-up will not be a feasible task. Knowing that mass within the Einstein radius has low systematic errors will add further significance to cosmological models constrained by strong lensing masses. However, these low errors lie on top of statistical errors and systematics due to structure along the line of sight. We note that we only investigated the mass profile of a single, massive cluster in this work. It would be important in future work to test if this result holds for less massive clusters that lens only a handful of images.

\subsection{Improving magnification estimates}
We find that the regions of the lens map with the highest systematic error are those close to the critical curve and/or along portions with significant curvature where the shear is high and there are few multiple images. The lowest error regions are those covered by multiple images, along portions of the critical curve that are straight. We found that models with low $N$ and low $n$ tend to estimate lower magnifications overall. As we saw, the free parameter redshifts solved for in models with many free parameter redshifts tend to be biased high, which results in a lower mass and thus lower magnification, which matches the trends we see in Figures Figure~\ref{chap3:fig:dlsds}-Figure~\ref{chap3:fig:histograms}. While mostly qualitative, this information is useful for anyone questioning the accuracy of a magnification value. While it is trivial to estimate the magnification and statistical uncertainties for a single image plane position by blindly computing it for one pixel in a magnification map, one needs to consider the pixel position within the full image plane to begin estimating the systematics.

\subsection{Models without spectroscopic redshifts}
Since the deflection angle depends on source redshift, the mass estimate within the Einstein radius depends on the redshift of the multiple images. If the redshift of the source is unknown, then the mass is degenerate with redshift. Therefore, lens models need at least one spectroscopic redshift to break the degeneracy. We test this theory by running models without spectroscopic redshifts and find that it is indeed the case that models built with even a handful of spectroscopic redshifts outperform all models built without any spectroscopic redshifts across all of our diagnostics. The models tend to predict redshifts that are higher than truth for nearly every image system, and therefore under-predict the mass by up to 10\% at the Einstein radius, and produce magnifications that can be either highly under- or over-predicted depending on the selection of constraints. When also factoring in statistical errors, which are high for low $N$ systems, and other systematics like structure along the line-of-sight, any lensing outputs from models with no spectroscopic redshifts should be treated with caution.

\begin{figure*}
\center
\includegraphics[width=0.8\textwidth]{Chap3/c3f10.pdf}
\caption[Relative magnification error of single model with increasing spec-z fraction]{The relative magnification error in ($z=2$) for the region of pixels shown in Figure~\ref{chap3:fig:hst} versus fraction of spectroscopic redshift systems for six lens models built using the same 25 image systems. The first model uses no spectroscopic redshifts, the second model adds spectroscopic redshifts to 5 systems, the third model adds spectroscopic redshifts to 5 more systems (10 total), etc. until all systems have spectroscopic redshifts. The errors are with respect to the model with all 25 spectroscopic redshift systems. The values are the median and $1\sigma$ range of values with the region of the best fit model. The gray contours represent the 1,2, and 3$\sigma$ statistical errors estimated from the MCMCs. The top row shows the image plane positions of the images from the 25 systems used as constraints. The blue and red points represent systems with and without spectroscopic redshifts, respectively. Each map is $200"\times200"$ centered on the origin defined in Figure~\ref{chap3:fig:hst}. The green solid and dashed lines indicate the locations of the $z=2$ critical curve and region of multiple images, respectively. The colored circles represent models using the same constraints as the models shown in the maps above; however, photometric redshift measurements are used as the priors for the free parameter redshifts rather than a uniform random prior. The colors indicate the rms error in the photometric redshifts used for that particular model: $(z_\mathrm{spec}-z_\mathrm{phot})/(1+z_\mathrm{spec})$ (see \S~\ref{chap3:subsec:photoz}).}
\label{chap3:fig:single_compare}
\end{figure*}

\subsection{Increasing the number of spectroscopic redshifts in a single model}
\label{chap3:subsec:n_specz}
Our results in \S\ref{chap3:subsec:magnification} showed that there was no trend in systematic errors on magnification with the fraction of spectroscopic redshifts used in a model when considering random selections of $n,m$. However, in cluster lensing scenarios similar to the HFF, the selection of image systems mostly stays the same and the fraction of spectroscopic redshifts $n/N$ increases over time as more spectroscopic data are collected. On-going lensing analyses of the HFF have so far indicated that increasing the fraction of spectroscopic redshifts for a given cluster may decrease systematic errors on its lens models. The tensions between observations of Supernova Tomas in Abell 2744 and Supernova Refsdal in MACS J1149.6+2223 and the predictions from several different lens models (i.e., magnification, time delays) have weak negative correlations with fraction of spectroscopic redshifts \citep{Rodney:2015uq,Rodney:2016sf}. In this scenario, the lens models are built by different teams using nearly the exact same identifications of multiple image systems, with some models including new spectroscopic systems in addition to existing sets.

To test whether we see this trend in the simulations, we design a set of lens models that represent a progression in increasing spectroscopic redshift fraction. We construct six new lens models of Ares each using the same set of 25 image systems. The first model is constructed without any spectroscopic redshifts, the second adds spectroscopic redshifts to 5 of these systems, the third adds an additional 5 spectroscopic redshifts to the existing 5 (10 total), etc., until all image systems have spectroscopic redshifts. The 25 systems and each addition of spectroscopic systems are selected carefully in order to maintain a roughly uniform distribution of locations in the image plane and of redshift. Figure~\ref{chap3:fig:single_compare} shows the magnification error of these models with respect to the model with $n=N$, in the same manner as Figure~\ref{chap3:fig:specz_fraction}. Here, it is clear that the accuracy of the magnification estimates improves with increasing $n/N$, indicating that measuring the spectroscopic redshifts of known lensed galaxies that are used as constraints will help decrease systematic errors while the precision is set based on the total number of systems. This result is consistent with those of \citet{Rodney:2015uq,Rodney:2016sf}, but shows a much stronger correlation. It is likely that the trends in the HFF models are weakened by systematics in the modeling methods themselves and that the selection of constraints were not exactly identical between models.

It is still important to note, however, that the model with $n=N$ is offset in magnification error from the fiducial model by about -0.01 mag. This result is expected, as we saw in Figure~\ref{chap3:fig:histograms} that models with $n=25,m=0$ have a systematic error of 0.02 mag with respect to the fiducial. With this in mind, increasing $n/N$ for a single model is most effective at decreasing systematic errors in magnification up to about $n/N\sim0.5$. Beyond that, the exact selection of all the image systems used in the model is a more significant source of systematic error.

While an investigation of the effect of photometric redshift information is beyond the scope of this paper, we do include a test case where we constrain the free redshift parameters with priors from photometric redshift catalogs. This preliminary analysis indicates that photometric redshifts may increase the accuracy of the lens model, but can also result in significantly inaccurate results if not handled with care. We discuss this in \S~\ref{chap3:subsec:photoz} below.

\section{Future work}
\label{chap3:sec:future}
While we have begun to thoroughly investigate the systematics of lens modeling in this paper, there are still many contributing factors we have not yet explored. Here, we considered how using different random subsets of spectroscopic and free parameter redshift image systems in a strong lens model affects the resulting multiple image predictability, mass profiles, and magnifications. As stated above, these results suggest that the exact selection of constraints and redshift information may be more influential on systematic errors then quantity, especially for the values of the magnification. Thus, we plan to follow up investigations of constraint selection in our continuation of this work.

\subsection{Observational limits on constraint selection}
We know the selection of multiple image systems is not random by any means and is a function of image brightness, which depends on the source's intrinsic brightness, luminosity distance from observer, and magnification induced by the galaxy cluster. The faintest observed images are less likely to be identified as multiple images. Similarly, obtaining spectroscopic redshifts can depend on image brightness, redshift, and image plane position. Multi-object spectrographs are limited in slit-packing capabilities and may only target the brightest systems for redshift measurements. Spectra of images close to cluster member galaxies might be contaminated, for which may make determining a redshift more difficult. \hst\ grism spectroscopy and integral field spectrographs are able to target many more images; however, they tend to have a limited total field-of-view. Additionally, completeness of spectroscopic redshifts depends on redshift as bright emission lines get shifted out of the instrument's wavelength coverage for certain redshifts, the so-called ``redshift desert" where redshifts become more challenging to measure. Factoring these selection effects could highlight position and redshift dependencies on the systematic error induced by spectroscopic selection effects.

\subsection{Photometric redshifts}
\label{chap3:subsec:photoz}
The current analysis clearly leaves out possible useful information in the form of photometric redshifts; these are typically available for clusters with extensive multiwavelength imaging data. Photometric redshift measurements are prone to their own systematic errors, and while these measurements can become more precise with increased number of bandpasses and deeper data, catastrophic failures can still occur. Photometric redshift measurements can be implemented in the lens modeling process by using the posterior probability distribution for the photometric redshift as the prior for the free parameter redshift in the lens modeling. While we leave a thorough investigation of the affect of photometric redshifts on lensing systematics for future work, we present here a case study.

We re-run the models we used in \S~\ref{chap3:subsec:n_specz} with $n=0$ and $n=10$ three more times using different realistic photometric redshift estimates for the priors of images without spectroscopic redshifts. In this experiment, the lensed galaxies used as constraints with spectroscopic redshifts are treated the same as before. However, lensed galaxies without spectroscopic redshifts are not assigned a uniform random prior on their free parameter redshift, but rather a gaussian prior centered on an assumed photometric redshift. We use the ASTRODEEP photometric redshift catalogs for HFF clusters Abell 2744 and MACS J0416 \citep{Castellano:2016lr} to determine our realistic photometric redshift measurements, and supplement the spectroscopic redshift sample of MACS 0416 with the MUSE redshifts measured by \citet{Caminha:2016fk}. We use the spectroscopic and photometric catalogs from this sample to estimate the accuracy of a photometric redshift given its true redshift. For each galaxy in our models of Ares where we do not include the spectroscopic redshift as a constraint, we draw a galaxy from the ASTRODEEP catalog with a similar spectroscopic redshift to its true redshift in the Ares simulation (within $0.04(1+z_\mathrm{true})$). We then assign the photometric redshift estimate obtained for that ASTRODEEP galaxy as the center of gaussian prior for the Ares galaxy. We assign a typical statistical error on photometric redshifts from the ASTRODEEP catalog as the width of the gaussian prior (these errors can vary significantly from galaxy to galaxy and across redshifts, from a few percent to up to 50\%.) This procedure results in a realistic representation of scatter of photometric redshift values at a fixed spectroscopic redshift, as well as the rate of catastrophic failures in fields that are by construction similar to our simulation. We include these models in Figure~\ref{chap3:fig:single_compare} as colored circles, where the color matches the rms error in photometric redshift. The results show that photometric redshifts can improve the lens modeling process, however, only when the photometric redshifts are relatively accurate. As shown in Figure~\ref{chap3:fig:single_compare}, using only photometric redshift priors can actually increase systematic errors in magnification over the use of broad uniform random priors when there are catastrophic failures in the photometric redshift measurements. One of the models we used had no spectroscopic redshifts and a photometric redshift rms error of 0.18, including a catastrophic failure with $z_\mathrm{phot} = 1.06$ for $z_\mathrm{spec} = 5.34$. This model produced a worse systematic offset in magnifications compared to the fiducial model. After adding 10 spectroscopic redshifts, the rms error dropped to 0.06, likely the result of replacing a catastrophic failure photometric redshift measurement with the true redshift of that system. The resulting model performs slightly better than the model without any photometric redshift information. The two other models with no spectroscopic redshifts had a moderate rms error (0.12) and reduced the systematic error by 0.01-0.02 dex, but did not perform significantly better after adding more spectroscopic redshifts. Photometric redshifts have the highest impact on modeling when there are few to no spectroscopic redshifts; however, this only improves the model if those photometric redshifts are reasonably accurate.

It is worth noting that there are a few aspects of including photometric redshifts in lens modeling that are difficult to simulate because they are highly dependent on the experience of the lens modeler. In the case of the catastrophic failure like in one of the models we tested, it is quite likely a lens modeler would have rejected any low-redshift solutions that are inconsistent with the lensing geometry based on a model produced by the other images with reasonable photometric redshifts (the $z=5$ critical curve has a much larger extent than the $z=1$ critical curve so the multiple images should be closer together). We also are not considering that the individual images may have different photometric redshift estimates. Brighter images may have more robust redshifts while fainter or contaminated images may produce wildly different photometric redshifts. A system of images with significantly different photometric redshifts may be less likely to be identified as a system and therefore not used in the lens model. It is unclear at this point how much more photometric redshifts will improve lens modeling if they are not reasonably accurate. However, future purely photometric surveys will have few if no spectroscopic redshifts for the many thousands of lensing clusters predicted to be found. Thus, it is important to investigate how photometric redshifts impact lens modeling and we plan to do so more extensively in future work.

\subsection{Image multiplicity and misidentified multiple images}
Our analysis in this paper investigated how the number of multiple image systems affects the systematic errors in lens modeling. However, we assume that every image system is equal in constraining power and that each system has been correctly identified. In reality, image systems with higher multiplicity (e.g., 4-image systems versus 2-image systems) have a higher weight in the lens modeling. Additionally, higher multiplicity image systems are likely to include radial arcs that will have higher constraining power on the inner slope of the mass profile. From the suite of 350 models we ran, the average image multiplicity (i.e., average number of images per system) ranged from 2.8 to 3.8 for all combinations of $n,m$. We found no trend in systematic errors in the inner and outer slopes of the mass profile nor the magnifications with average image multiplicity. It is possible trends could occur when the number of image systems is fewer than five, which was the lowest number of systems we investigated. Thus, image multiplicity should be investigated in future work with clusters that have very few multiple image systems to constrain lens models.

We did not account for image identification error in our analysis. The faintest images of a single system are the most likely to be misidentifed as they can easily confused with other background sources or blended with foreground objects. As stated in \S~\ref{chap3:subsec:fiducial_model}, we did not include some of these images that are likely to be misidentified in our models. Therefore, our results show the best case scenario when lens modelers use only the highest-confidence images in their lens models. Simulating the effects of misidentification could be done in future work by comparing models where the faintest image system is perturbed by a several arcseconds or not included in the model.

\subsection{Image plane and redshift distribution of lensing constraints}
For models with smaller numbers of image systems, it is important to assess how the spatial distribution of image systems in the image plane affects systematic errors. We found in this work that many of the outlier test models in mass and magnification had uneven spatial distribution of spectroscopic systems. We also saw that models with smaller $N$ had larger spread in mass and magnification, as the spatial distribution of the constraints can vary significantly from model to model. As more constraints are added, constraints will more evenly populate the multiple image region. Ares simulates a very massive cluster and it is likely that a cluster of this size will lens more than a handful of image systems. Therefore, we did not attempt to model Ares using fewer than five image systems. We would consider instead modeling a less massive cluster to assess how image plane distribution affects the outcome of a lens model.

As we found in this analysis, the elongated mass distribution of Ares across the sky creates an elliptical critical curve, where the magnification errors are lowest along the straight portions of the critical curve. These elongated mass distributions are common amongst the HFF clusters, which lie at the cusp of mass assembly in the nodes of the cosmic web. It would be interesting to investigate systematics on clusters with more spherical mass distributions. A prime example would be Abell 1689, which has a large number of identified image systems with spectroscopic redshifts and for which existing lens models suggest it has a more circular critical curve \citep{Diego:2015tg,Coe:2010fy,Limousin:2007fk,Broadhurst:2005qy}.

The redshift distribution of lensed sources could potentially increase systematic error as well. The sources used in Ares were well distributed across redshifts from $z\sim0.9-6$; however, this is not the case in reality as the luminosity function of galaxies and the area of the caustic region both depend on redshift. There is an observational bias toward selecting the brightest sources, and as lensing conserves surface brightness, this leads to a higher likelihood of low redshift sources being identified and used as constraints in a model. We found that some models that were outliers in our analysis for a given $n,m$ had uneven distributions in redshifts. It is well known that multiple redshifts of sources are needed to establish the slope of the mass distribution in a lens model \citep[i.e., break the mass-sheet degeneracy, see][]{Schneider:1995vn}. In cases where all the lensed sources are low redshift, it is possible to extrapolate the mass to larger Einstein radii and thus predict the magnification of higher redshift sources; however, the accuracy of doing so is unknown and is worth investigating in the future.

\vspace{6pt}

For clusters such as Ares, built to resemble massive lensing clusters such as the HFF, it is safe to say that there will be a wealth of constraints across the image plane and redshift space. More massive clusters have a larger lensing cross section and thus have access to a much larger volume of background sources from which to lens. The investigations into image plane and redshift distribution of lensing constraints is best left to more average mass clusters, which will likely only lens a handful of sources. As Ares is too massive to investigate the parameter space of $N<5$, these questions call for a different design in cluster lensing simulations and are best left for future studies.

%==================================================================================
%  CONCLUSION
%==================================================================================
\section{Conclusion}

We have investigated the systematic errors of parametric strong lensing modeling induced by selection of constraints using our ``unblinded" model of the simulated cluster Ares \citep{Meneghetti:2016xe}. Here we summarize our findings:

\begin{enumerate}
\item The image plane rms based on the full lensing evidence, i.e., the image predictive power of a lens model, improves mostly effectively with increasing number of spectroscopic redshift image systems. This result indicates the necessity for obtaining spectroscopic redshifts early on in the modeling process, as they are crucial to increasing the accuracy of finding new multiple image systems. We also have shown, however, that the image plane rms values quoted in the literature, which are computed only from image systems used in the model using best fit model redshifts, shows the opposite trend. While lower values of the rms computed this way reveal a better model fit with more free parameters and fewer constraints, it can be misleading as a measure of model accuracy.
\item Lens models with at least a handful of spectroscopic redshifts are able to predict the redshifts of image systems without spectroscopic redshifts within 2\% (in $\dls/\ds$); however, they are generally biased higher for image systems with $z>2$.
\item The mass profiles are accurately measured for all variations of lens model constraints with $n>0$: $<4\%$ error within 1 Mpc and $<2\%$ at the cluster Einstein radius.
\item Qualitatively, the magnification error is lowest in regions of the image plane where the multiple images are located and typically along the straight portions of the critical curve. The magnification error is larger at the curved portions of the critical curve and typically biased toward lower values.
\item The accuracy of magnifications increases with total number of image systems, and for $N>20$ plateaus to 2\%. We observe no trend in magnification accuracy with fraction of spectroscopic redshift when comparing models in which $n,m$ are chosen randomly, as long as this fraction is greater than zero. However, we do find that for a model with a fixed set of multiple images, increasing the fraction of systems with spectroscopic redshifts helps improve the accuracy while maintaining nearly a constant level of precision.
\item Lens models need at least a few spectroscopic systems in order to produce reasonable estimates of the mass and magnification. Models computed without spectroscopic redshifts are biased toward lower masses ($5-10\%$) and lower magnifications ($>2\%$). The systematic error will be lower for models that use more image systems; however, models built using many image systems without spectroscopic redshifts still produce higher errors than models with only a handful of spectroscopic redshifts.
\item Photometric redshifts can be implemented in lens modeling to improve upon the systematic errors on magnification, especially when there are no spectroscopic data available for the constraints. However, inaccurate photometric redshifts (i.e., catastrophic failures) can actually inflate the systematic errors of a lens model.
\end{enumerate}

Based on our findings, we put forth the following recommendations with regards to strong lens modeling:

\begin{enumerate}
\item  After obtaining new spectroscopic redshifts, newer iterations on existing lens models should be reconstructed using only spectroscopic systems first before including systems with no spectroscopic redshifts as constraints. This method will likely lead to a higher success rate of finding correct multiple image systems.
\item For models with many unknown redshifts report the image plane rms computed for only systems with spectroscopic redshifts as a means to measure model predictions locations of images versus the truth.
\item In circumstances where there are ample numbers of image systems ($N>25$) it may be advantageous to include only the highest confidence image systems (those that are spectroscopically confirmed and/or wholly unambiguous by color and morphology), as removing less confident images may decrease systematics more than the cost of increasing statistical errors.
\item Simply selecting a value from a best fit model and quoting only statistical errors is not enough for properly estimating magnifications of background sources, one needs to assess the location of that object within the image plane (assuming the source redshift is known) as well and determine whether or not a pure strong lensing analysis is enough to estimate the magnification.
\end{enumerate}

While we have discussed the impact of constraint selection on systematic errors, there are many sources of error we leave to discuss in future papers, i.e., image plane distribution of constraints, redshift and brightness-dependent selections, photometric redshifts as constraints, unmodeled line-of-sight substructure \citep[e.g.,][]{DAloisio:2014vl}, cluster substructure \citep[e.g.,][]{Limousin:2007fk}, cosmological parameter uncertainty \citep[e.g.,][]{Bayliss:2015lr}, and choice of lensing algorithm \citep{Meneghetti:2016xe}, which we have not quantified here. Additionally, we would like to extend these studies to real clusters in the field and to less massive clusters that represent a larger fraction of the cluster population.
